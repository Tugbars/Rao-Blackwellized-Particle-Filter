{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBPF Comprehensive Comparison Analysis\n",
    "\n",
    "Compares 4 configurations:\n",
    "1. **Baseline** - RBPF alone, no parameter learning\n",
    "2. **Liu-West** - RBPF + Liu-West shrinkage learning\n",
    "3. **Storvik** - RBPF + Sleeping Storvik learning\n",
    "4. **Storvik+APF** - Full stack with lookahead\n",
    "\n",
    "Analysis covers:\n",
    "- Volatility tracking accuracy\n",
    "- Regime detection performance\n",
    "- Parameter learning convergence\n",
    "- Latency distribution\n",
    "- Scenario-specific behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Color scheme for 4 modes\n",
    "COLORS = {\n",
    "    'baseline': '#1f77b4',    # Blue\n",
    "    'liu_west': '#ff7f0e',    # Orange\n",
    "    'storvik': '#2ca02c',     # Green\n",
    "    'storvik_apf': '#d62728'  # Red\n",
    "}\n",
    "LABELS = {\n",
    "    'baseline': 'Baseline',\n",
    "    'liu_west': 'Liu-West',\n",
    "    'storvik': 'Storvik',\n",
    "    'storvik_apf': 'Storvik+APF'\n",
    "}\n",
    "\n",
    "# Load data\n",
    "dfs = {\n",
    "    'baseline': pd.read_csv('rbpf_baseline.csv'),\n",
    "    'liu_west': pd.read_csv('rbpf_liu_west.csv'),\n",
    "    'storvik': pd.read_csv('rbpf_storvik.csv'),\n",
    "    'storvik_apf': pd.read_csv('rbpf_storvik_apf.csv')\n",
    "}\n",
    "df_summary = pd.read_csv('rbpf_comparison_summary.csv')\n",
    "\n",
    "print(f\"Loaded {len(dfs['baseline'])} ticks per mode\")\n",
    "print(f\"\\nSummary metrics:\")\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Volatility Tracking Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12), sharex=True)\n",
    "\n",
    "# Use baseline for ground truth\n",
    "df_base = dfs['baseline']\n",
    "\n",
    "# True volatility\n",
    "ax = axes[0]\n",
    "ax.plot(df_base['tick'], df_base['true_vol'], 'k-', linewidth=1, label='True Vol', alpha=0.8)\n",
    "for key in dfs:\n",
    "    ax.plot(dfs[key]['tick'], dfs[key]['est_vol'], color=COLORS[key], \n",
    "            linewidth=0.7, alpha=0.6, label=LABELS[key])\n",
    "ax.set_ylabel('Volatility')\n",
    "ax.set_title('Volatility Tracking: All Methods')\n",
    "ax.legend(loc='upper right', ncol=5)\n",
    "ax.set_ylim(0, 0.5)\n",
    "\n",
    "# Log-volatility\n",
    "ax = axes[1]\n",
    "ax.plot(df_base['tick'], df_base['true_log_vol'], 'k-', linewidth=1, label='True', alpha=0.8)\n",
    "for key in dfs:\n",
    "    ax.plot(dfs[key]['tick'], dfs[key]['est_log_vol'], color=COLORS[key], \n",
    "            linewidth=0.7, alpha=0.6, label=LABELS[key])\n",
    "ax.set_ylabel('Log-Volatility')\n",
    "ax.set_title('Log-Volatility Tracking')\n",
    "ax.legend(loc='upper right', ncol=5)\n",
    "\n",
    "# True regime (background)\n",
    "ax = axes[2]\n",
    "ax.fill_between(df_base['tick'], df_base['true_regime'], alpha=0.3, color='gray', label='True Regime')\n",
    "for key in dfs:\n",
    "    ax.plot(dfs[key]['tick'], dfs[key]['est_regime'], color=COLORS[key], \n",
    "            linewidth=0.7, alpha=0.7, label=LABELS[key])\n",
    "ax.set_ylabel('Regime')\n",
    "ax.set_xlabel('Tick')\n",
    "ax.set_title('Regime Detection')\n",
    "ax.set_yticks([0, 1, 2, 3])\n",
    "ax.legend(loc='upper right', ncol=5)\n",
    "\n",
    "# Add scenario markers\n",
    "scenario_boundaries = [1000, 2000, 2500, 3500, 4500, 5000]\n",
    "for ax in axes:\n",
    "    for b in scenario_boundaries:\n",
    "        ax.axvline(b, color='gray', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rbpf_comparison_overview.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tracking Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Compute errors\n",
    "errors = {}\n",
    "for key in dfs:\n",
    "    errors[key] = dfs[key]['est_log_vol'] - dfs[key]['true_log_vol']\n",
    "\n",
    "# Rolling RMSE (window=100)\n",
    "ax = axes[0, 0]\n",
    "window = 100\n",
    "for key in dfs:\n",
    "    rolling_rmse = np.sqrt((errors[key]**2).rolling(window).mean())\n",
    "    ax.plot(dfs[key]['tick'], rolling_rmse, color=COLORS[key], label=LABELS[key], alpha=0.8)\n",
    "ax.set_ylabel('Rolling RMSE')\n",
    "ax.set_xlabel('Tick')\n",
    "ax.set_title(f'Log-Vol Rolling RMSE (window={window})')\n",
    "ax.legend()\n",
    "\n",
    "# Error distribution (histogram)\n",
    "ax = axes[0, 1]\n",
    "for key in dfs:\n",
    "    ax.hist(errors[key], bins=50, alpha=0.5, color=COLORS[key], label=LABELS[key])\n",
    "ax.set_xlabel('Log-Vol Error')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Error Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# RMSE bar chart\n",
    "ax = axes[1, 0]\n",
    "rmse_values = [np.sqrt((errors[key]**2).mean()) for key in dfs]\n",
    "bars = ax.bar(range(4), rmse_values, color=[COLORS[k] for k in dfs])\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels([LABELS[k] for k in dfs])\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Log-Vol RMSE Comparison')\n",
    "for i, v in enumerate(rmse_values):\n",
    "    ax.text(i, v + 0.005, f'{v:.4f}', ha='center', fontsize=9)\n",
    "\n",
    "# MAE bar chart\n",
    "ax = axes[1, 1]\n",
    "mae_values = [errors[key].abs().mean() for key in dfs]\n",
    "bars = ax.bar(range(4), mae_values, color=[COLORS[k] for k in dfs])\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels([LABELS[k] for k in dfs])\n",
    "ax.set_ylabel('MAE')\n",
    "ax.set_title('Log-Vol MAE Comparison')\n",
    "for i, v in enumerate(mae_values):\n",
    "    ax.text(i, v + 0.005, f'{v:.4f}', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rbpf_comparison_errors.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nLog-Vol Error Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "for key in dfs:\n",
    "    e = errors[key]\n",
    "    print(f\"\\n{LABELS[key]:15s}: RMSE={np.sqrt((e**2).mean()):.4f}, MAE={e.abs().mean():.4f}, Bias={e.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regime Detection Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Regime accuracy over time (rolling)\n",
    "ax = axes[0, 0]\n",
    "window = 200\n",
    "for key in dfs:\n",
    "    correct = (dfs[key]['est_regime'] == dfs[key]['true_regime']).astype(float)\n",
    "    rolling_acc = correct.rolling(window).mean() * 100\n",
    "    ax.plot(dfs[key]['tick'], rolling_acc, color=COLORS[key], label=LABELS[key], alpha=0.8)\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_xlabel('Tick')\n",
    "ax.set_title(f'Rolling Regime Accuracy (window={window})')\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "# Overall accuracy bar chart\n",
    "ax = axes[0, 1]\n",
    "acc_values = [(dfs[key]['est_regime'] == dfs[key]['true_regime']).mean() * 100 for key in dfs]\n",
    "bars = ax.bar(range(4), acc_values, color=[COLORS[k] for k in dfs])\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels([LABELS[k] for k in dfs])\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Overall Regime Accuracy')\n",
    "for i, v in enumerate(acc_values):\n",
    "    ax.text(i, v + 1, f'{v:.1f}%', ha='center', fontsize=9)\n",
    "\n",
    "# Confusion matrix for best method (Storvik)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ax = axes[1, 0]\n",
    "df_best = dfs['storvik']\n",
    "cm = confusion_matrix(df_best['true_regime'], df_best['est_regime'], labels=[0,1,2,3])\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Greens', ax=ax,\n",
    "            xticklabels=['R0', 'R1', 'R2', 'R3'],\n",
    "            yticklabels=['R0', 'R1', 'R2', 'R3'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix (Storvik)')\n",
    "\n",
    "# ESS comparison\n",
    "ax = axes[1, 1]\n",
    "ess_values = [dfs[key]['ess'].mean() for key in dfs]\n",
    "bars = ax.bar(range(4), ess_values, color=[COLORS[k] for k in dfs])\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels([LABELS[k] for k in dfs])\n",
    "ax.set_ylabel('Average ESS')\n",
    "ax.set_title('Effective Sample Size')\n",
    "for i, v in enumerate(ess_values):\n",
    "    ax.text(i, v + 5, f'{v:.0f}', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rbpf_comparison_regime.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parameter Learning Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth parameters\n",
    "TRUE_MU_VOL = {0: -4.6, 1: -3.5, 2: -2.5, 3: -1.5}\n",
    "TRUE_SIGMA_VOL = {0: 0.05, 1: 0.10, 2: 0.20, 3: 0.35}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# mu_vol R0 learning\n",
    "ax = axes[0, 0]\n",
    "ax.axhline(TRUE_MU_VOL[0], color='black', linestyle='--', linewidth=2, label='True μ_vol R0')\n",
    "for key in ['liu_west', 'storvik', 'storvik_apf']:\n",
    "    if 'learned_mu_vol_r0' in dfs[key].columns:\n",
    "        ax.plot(dfs[key]['tick'], dfs[key]['learned_mu_vol_r0'], \n",
    "                color=COLORS[key], label=LABELS[key], alpha=0.8)\n",
    "ax.set_ylabel('μ_vol (R0)')\n",
    "ax.set_xlabel('Tick')\n",
    "ax.set_title('Parameter Learning: μ_vol (Calm Regime)')\n",
    "ax.legend()\n",
    "\n",
    "# mu_vol R3 learning\n",
    "ax = axes[0, 1]\n",
    "ax.axhline(TRUE_MU_VOL[3], color='black', linestyle='--', linewidth=2, label='True μ_vol R3')\n",
    "for key in ['liu_west', 'storvik', 'storvik_apf']:\n",
    "    if 'learned_mu_vol_r3' in dfs[key].columns:\n",
    "        ax.plot(dfs[key]['tick'], dfs[key]['learned_mu_vol_r3'], \n",
    "                color=COLORS[key], label=LABELS[key], alpha=0.8)\n",
    "ax.set_ylabel('μ_vol (R3)')\n",
    "ax.set_xlabel('Tick')\n",
    "ax.set_title('Parameter Learning: μ_vol (Crisis Regime)')\n",
    "ax.legend()\n",
    "\n",
    "# Final parameter error comparison\n",
    "ax = axes[1, 0]\n",
    "keys_learn = ['liu_west', 'storvik', 'storvik_apf']\n",
    "mu_r0_errors = []\n",
    "mu_r3_errors = []\n",
    "for key in keys_learn:\n",
    "    if 'learned_mu_vol_r0' in dfs[key].columns:\n",
    "        final_mu_r0 = dfs[key]['learned_mu_vol_r0'].iloc[-1]\n",
    "        final_mu_r3 = dfs[key]['learned_mu_vol_r3'].iloc[-1]\n",
    "        mu_r0_errors.append(abs(final_mu_r0 - TRUE_MU_VOL[0]))\n",
    "        mu_r3_errors.append(abs(final_mu_r3 - TRUE_MU_VOL[3]))\n",
    "    else:\n",
    "        mu_r0_errors.append(0)\n",
    "        mu_r3_errors.append(0)\n",
    "\n",
    "x = np.arange(len(keys_learn))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, mu_r0_errors, width, label='R0 Error', color='steelblue')\n",
    "ax.bar(x + width/2, mu_r3_errors, width, label='R3 Error', color='coral')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([LABELS[k] for k in keys_learn])\n",
    "ax.set_ylabel('|Error|')\n",
    "ax.set_title('Final μ_vol Parameter Error')\n",
    "ax.legend()\n",
    "\n",
    "# Learning speed (ticks to reach within 10% of true)\n",
    "ax = axes[1, 1]\n",
    "# Placeholder - would need to compute convergence time\n",
    "ax.text(0.5, 0.5, 'Learning\\nConvergence\\nAnalysis', \n",
    "        ha='center', va='center', fontsize=14, transform=ax.transAxes)\n",
    "ax.set_title('Convergence Speed (placeholder)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rbpf_comparison_learning.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Print final learned parameters\n",
    "print(\"\\nFinal Learned Parameters:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Method':15s} {'μ_vol R0':>12s} {'True':>8s} {'μ_vol R3':>12s} {'True':>8s}\")\n",
    "print(\"-\" * 60)\n",
    "for key in keys_learn:\n",
    "    if 'learned_mu_vol_r0' in dfs[key].columns:\n",
    "        mu_r0 = dfs[key]['learned_mu_vol_r0'].iloc[-1]\n",
    "        mu_r3 = dfs[key]['learned_mu_vol_r3'].iloc[-1]\n",
    "        print(f\"{LABELS[key]:15s} {mu_r0:12.4f} {TRUE_MU_VOL[0]:8.2f} {mu_r3:12.4f} {TRUE_MU_VOL[3]:8.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Latency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Histogram comparison\n",
    "ax = axes[0, 0]\n",
    "for key in dfs:\n",
    "    ax.hist(dfs[key]['latency_us'], bins=50, alpha=0.5, color=COLORS[key], \n",
    "            label=f\"{LABELS[key]} (μ={dfs[key]['latency_us'].mean():.1f}μs)\")\n",
    "ax.set_xlabel('Latency (μs)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Latency Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# Box plot\n",
    "ax = axes[0, 1]\n",
    "data_box = [dfs[key]['latency_us'] for key in dfs]\n",
    "bp = ax.boxplot(data_box, labels=[LABELS[k] for k in dfs], patch_artist=True)\n",
    "for i, (box, key) in enumerate(zip(bp['boxes'], dfs.keys())):\n",
    "    box.set_facecolor(COLORS[key])\n",
    "    box.set_alpha(0.6)\n",
    "ax.set_ylabel('Latency (μs)')\n",
    "ax.set_title('Latency Box Plot')\n",
    "\n",
    "# Percentile comparison\n",
    "ax = axes[1, 0]\n",
    "percentiles = [50, 75, 90, 95, 99]\n",
    "x = np.arange(len(percentiles))\n",
    "width = 0.2\n",
    "for i, key in enumerate(dfs):\n",
    "    p_vals = [np.percentile(dfs[key]['latency_us'], p) for p in percentiles]\n",
    "    ax.bar(x + i*width - 1.5*width, p_vals, width, label=LABELS[key], color=COLORS[key], alpha=0.8)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'P{p}' for p in percentiles])\n",
    "ax.set_ylabel('Latency (μs)')\n",
    "ax.set_title('Latency Percentiles')\n",
    "ax.legend()\n",
    "\n",
    "# Average latency bar\n",
    "ax = axes[1, 1]\n",
    "avg_lat = [dfs[key]['latency_us'].mean() for key in dfs]\n",
    "p99_lat = [dfs[key]['latency_us'].quantile(0.99) for key in dfs]\n",
    "x = np.arange(4)\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, avg_lat, width, label='Mean', color='steelblue')\n",
    "ax.bar(x + width/2, p99_lat, width, label='P99', color='coral')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([LABELS[k] for k in dfs])\n",
    "ax.set_ylabel('Latency (μs)')\n",
    "ax.set_title('Mean vs P99 Latency')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rbpf_comparison_latency.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Print latency statistics\n",
    "print(\"\\nLatency Statistics:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Method':15s} {'Mean':>10s} {'Median':>10s} {'P95':>10s} {'P99':>10s} {'Max':>10s}\")\n",
    "print(\"-\" * 70)\n",
    "for key in dfs:\n",
    "    lat = dfs[key]['latency_us']\n",
    "    print(f\"{LABELS[key]:15s} {lat.mean():10.2f} {lat.median():10.2f} {lat.quantile(0.95):10.2f} {lat.quantile(0.99):10.2f} {lat.max():10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scenario-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scenarios\n",
    "scenarios = [\n",
    "    ('1. Calm', 0, 1000),\n",
    "    ('2. Gradual Rise', 1000, 2000),\n",
    "    ('3. Sudden Crisis', 2000, 2500),\n",
    "    ('4. Crisis Persist', 2500, 3500),\n",
    "    ('5. Recovery', 3500, 4500),\n",
    "    ('6. Flash Crash', 4500, 5000),\n",
    "    ('7. Choppy', 5000, 7000)\n",
    "]\n",
    "\n",
    "# Compute metrics per scenario\n",
    "results = []\n",
    "for name, start, end in scenarios:\n",
    "    row = {'Scenario': name}\n",
    "    for key in dfs:\n",
    "        mask = (dfs[key]['tick'] >= start) & (dfs[key]['tick'] < end)\n",
    "        df_slice = dfs[key][mask]\n",
    "        \n",
    "        # Regime accuracy\n",
    "        acc = (df_slice['est_regime'] == df_slice['true_regime']).mean() * 100\n",
    "        row[f'{LABELS[key]} Acc'] = f'{acc:.1f}%'\n",
    "        \n",
    "        # Log-vol RMSE\n",
    "        rmse = np.sqrt(((df_slice['est_log_vol'] - df_slice['true_log_vol'])**2).mean())\n",
    "        row[f'{LABELS[key]} RMSE'] = f'{rmse:.3f}'\n",
    "    \n",
    "    results.append(row)\n",
    "\n",
    "df_scenarios = pd.DataFrame(results)\n",
    "print(\"\\nScenario-Specific Performance:\")\n",
    "print(\"=\" * 100)\n",
    "display(df_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario accuracy heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Build accuracy matrix\n",
    "acc_matrix = []\n",
    "for name, start, end in scenarios:\n",
    "    row = []\n",
    "    for key in dfs:\n",
    "        mask = (dfs[key]['tick'] >= start) & (dfs[key]['tick'] < end)\n",
    "        acc = (dfs[key][mask]['est_regime'] == dfs[key][mask]['true_regime']).mean() * 100\n",
    "        row.append(acc)\n",
    "    acc_matrix.append(row)\n",
    "\n",
    "acc_matrix = np.array(acc_matrix)\n",
    "sns.heatmap(acc_matrix, annot=True, fmt='.1f', cmap='RdYlGn',\n",
    "            xticklabels=[LABELS[k] for k in dfs],\n",
    "            yticklabels=[s[0] for s in scenarios],\n",
    "            vmin=40, vmax=100, ax=ax)\n",
    "ax.set_title('Regime Accuracy by Scenario (%)')\n",
    "ax.set_xlabel('Method')\n",
    "ax.set_ylabel('Scenario')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rbpf_comparison_scenario_heatmap.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Crisis Zoom: Sudden Crisis (Scenario 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom into sudden crisis transition\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "mask_range = (1900, 2200)  # Around the R2→R3 transition\n",
    "\n",
    "for key in dfs:\n",
    "    mask = (dfs[key]['tick'] >= mask_range[0]) & (dfs[key]['tick'] < mask_range[1])\n",
    "    df_zoom = dfs[key][mask]\n",
    "    \n",
    "    # Volatility\n",
    "    axes[0].plot(df_zoom['tick'], df_zoom['est_vol'], color=COLORS[key], \n",
    "                 label=LABELS[key], alpha=0.8, linewidth=1.5)\n",
    "    \n",
    "    # Regime\n",
    "    axes[1].plot(df_zoom['tick'], df_zoom['est_regime'], color=COLORS[key], \n",
    "                 label=LABELS[key], alpha=0.8, linewidth=1.5)\n",
    "    \n",
    "    # ESS\n",
    "    axes[2].plot(df_zoom['tick'], df_zoom['ess'], color=COLORS[key], \n",
    "                 label=LABELS[key], alpha=0.8, linewidth=1.5)\n",
    "\n",
    "# Add ground truth\n",
    "df_base = dfs['baseline']\n",
    "mask = (df_base['tick'] >= mask_range[0]) & (df_base['tick'] < mask_range[1])\n",
    "axes[0].plot(df_base[mask]['tick'], df_base[mask]['true_vol'], 'k--', linewidth=2, label='True')\n",
    "axes[1].fill_between(df_base[mask]['tick'], df_base[mask]['true_regime'], alpha=0.2, color='gray')\n",
    "\n",
    "axes[0].set_ylabel('Volatility')\n",
    "axes[0].set_title('Sudden Crisis Transition (tick 2000)')\n",
    "axes[0].legend(loc='upper left', ncol=5)\n",
    "axes[0].axvline(2000, color='red', linestyle=':', alpha=0.7)\n",
    "\n",
    "axes[1].set_ylabel('Regime')\n",
    "axes[1].set_yticks([0, 1, 2, 3])\n",
    "axes[1].legend(loc='upper left', ncol=5)\n",
    "axes[1].axvline(2000, color='red', linestyle=':', alpha=0.7)\n",
    "\n",
    "axes[2].set_ylabel('ESS')\n",
    "axes[2].set_xlabel('Tick')\n",
    "axes[2].legend(loc='upper left', ncol=5)\n",
    "axes[2].axvline(2000, color='red', linestyle=':', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rbpf_comparison_crisis_zoom.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Flash Crash Zoom (Scenario 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom into flash crash\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "mask_range = (4650, 4850)  # Flash crash at 4700-4750\n",
    "\n",
    "for key in dfs:\n",
    "    mask = (dfs[key]['tick'] >= mask_range[0]) & (dfs[key]['tick'] < mask_range[1])\n",
    "    df_zoom = dfs[key][mask]\n",
    "    \n",
    "    axes[0].plot(df_zoom['tick'], df_zoom['est_vol'], color=COLORS[key], \n",
    "                 label=LABELS[key], alpha=0.8, linewidth=1.5)\n",
    "    axes[1].plot(df_zoom['tick'], df_zoom['est_regime'], color=COLORS[key], \n",
    "                 label=LABELS[key], alpha=0.8, linewidth=1.5)\n",
    "    axes[2].plot(df_zoom['tick'], df_zoom['ess'], color=COLORS[key], \n",
    "                 label=LABELS[key], alpha=0.8, linewidth=1.5)\n",
    "\n",
    "# Ground truth\n",
    "df_base = dfs['baseline']\n",
    "mask = (df_base['tick'] >= mask_range[0]) & (df_base['tick'] < mask_range[1])\n",
    "axes[0].plot(df_base[mask]['tick'], df_base[mask]['true_vol'], 'k--', linewidth=2, label='True')\n",
    "axes[1].fill_between(df_base[mask]['tick'], df_base[mask]['true_regime'], alpha=0.2, color='gray')\n",
    "\n",
    "# Mark flash crash region\n",
    "for ax in axes:\n",
    "    ax.axvspan(4700, 4750, alpha=0.2, color='red')\n",
    "\n",
    "axes[0].set_ylabel('Volatility')\n",
    "axes[0].set_title('Flash Crash (ticks 4700-4750)')\n",
    "axes[0].legend(loc='upper right', ncol=5)\n",
    "\n",
    "axes[1].set_ylabel('Regime')\n",
    "axes[1].set_yticks([0, 1, 2, 3])\n",
    "axes[1].legend(loc='upper right', ncol=5)\n",
    "\n",
    "axes[2].set_ylabel('ESS')\n",
    "axes[2].set_xlabel('Tick')\n",
    "axes[2].legend(loc='upper right', ncol=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rbpf_comparison_flash_crash.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build comprehensive summary\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Log-Vol RMSE',\n",
    "        'Log-Vol MAE',\n",
    "        'Vol RMSE',\n",
    "        'Regime Accuracy',\n",
    "        'Avg ESS',\n",
    "        'Min ESS',\n",
    "        'Avg Latency (μs)',\n",
    "        'P99 Latency (μs)',\n",
    "        'Max Latency (μs)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "for key in dfs:\n",
    "    df = dfs[key]\n",
    "    log_err = df['est_log_vol'] - df['true_log_vol']\n",
    "    vol_err = df['est_vol'] - df['true_vol']\n",
    "    \n",
    "    summary_data[LABELS[key]] = [\n",
    "        f\"{np.sqrt((log_err**2).mean()):.4f}\",\n",
    "        f\"{log_err.abs().mean():.4f}\",\n",
    "        f\"{np.sqrt((vol_err**2).mean()):.6f}\",\n",
    "        f\"{(df['est_regime'] == df['true_regime']).mean()*100:.1f}%\",\n",
    "        f\"{df['ess'].mean():.1f}\",\n",
    "        f\"{df['ess'].min():.1f}\",\n",
    "        f\"{df['latency_us'].mean():.2f}\",\n",
    "        f\"{df['latency_us'].quantile(0.99):.2f}\",\n",
    "        f\"{df['latency_us'].max():.2f}\"\n",
    "    ]\n",
    "\n",
    "df_final = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "display(df_final)\n",
    "\n",
    "# Highlight winner for each metric\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSIONS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Key findings:\n",
    "1. Parameter Learning: Compare Liu-West vs Storvik convergence and final error\n",
    "2. Regime Detection: Which method tracks regime changes fastest?\n",
    "3. Latency: Does Storvik add significant overhead vs Liu-West?\n",
    "4. APF Benefit: Does lookahead help on top of Storvik?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "print(\"\\nSaved figures:\")\n",
    "print(\"  - rbpf_comparison_overview.png\")\n",
    "print(\"  - rbpf_comparison_errors.png\")\n",
    "print(\"  - rbpf_comparison_regime.png\")\n",
    "print(\"  - rbpf_comparison_learning.png\")\n",
    "print(\"  - rbpf_comparison_latency.png\")\n",
    "print(\"  - rbpf_comparison_scenario_heatmap.png\")\n",
    "print(\"  - rbpf_comparison_crisis_zoom.png\")\n",
    "print(\"  - rbpf_comparison_flash_crash.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
